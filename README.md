# SLM
# 서울대학교 연수 프로젝트

** 아래는 단순 Task별로 ToDo 항목을 구분지어 놓음.
   추후 필요 시 수정 가능

** 폴더 구조
 1) data : 뉴스기사 크롤링 데이터, ETF 종목 파일 저장
 2) DB : 뉴스 데이터, ETF 데이터 DB
 3) function : 별도 기능 (ex. 뉴스 데이터 필터링 포함 DB 조회, 추가 웹 크롤링 등) 구현
 4) 제일 바깥 메인 경로
    > streamlit : streamlit 라이브러리를 통해 대상 파일
    > main : 메인 화면 페이지
    > page_1, page_2 ,test : 목적에 맞춰 구현 예정중인 페이지
    


1. 데이터 수집
  - 뉴스기사 수집 : 한국경제 기준 뉴스기사 수집
  - ETF종목 수집 : 파일 형태로 수집 완료
    
2. 데이터 DB화 (DuckDB활용)
  - 뉴스기사를 DB에 저장
  - 고객 정보 DB화(가상시나리오 맞춰 저장)
  - ETF상품 정보
    
3. 데이터 조회 [필요 시 진행]
  - (ex) 종목에 맞춘 뉴스 데이터 추출

4. LLM 활용 ~ Langchain/Langgraph 라이브러리로 표준화 예정
  - RAG 파이프라인
  - Tool calling을 활용한 모델 결과 보완 
